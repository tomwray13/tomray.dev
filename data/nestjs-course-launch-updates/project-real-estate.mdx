---
title: 'Real estate listings - NestJS Starter'
h1: Real estate listings - NestJS Starter
date: '2023-07-23'
lastmod: '2023-07-23'
draft: false
summary: Real estate listings - NestJS Starter
images: ['/static/images/nestjs-cheat-sheet/banner.png']
isHiddenFromSearch: false
---

Please make sure you've installed the pre-requisites before starting!

## Intro

We're going to build a real-estate API that allows you to create real estate listings with photos. The photos are added to a queue for processing in the background (where we'll upload the file to Google Cloud Storage and store the public image url in the database).

Here are the topics and features we'll cover in this project:

- Handling and validating file uploads
- Sending files to a queue as jobs
- Processing the jobs in the background
- Viewing the queue jobs in a UI
- Using Google Cloud Storage to store the files
- Validation with DTOs and pipes
- Unit testing, integration testing and end-to-end testing

Let's get started by cloning the starter repo:

```bash
git clone CLONE_URL
```

Let's dive in!

- handle multiple file uploads for listing images with basic validation
  -- show using multi-part/form data requires a tweak to the DTO to transform strings to respective numbers
  -- add a custom pipe to validate number of files - FilesInterceptor argument is possible but the returned error is not clear
- register queue and send off images for processing
  -- The forRoot() method is used to register a bull package configuration object that will be used by all queues registered in the application. Applied in CommonModule
  -- notes on registering queue against same instance as Redis cache
- implement Bull Arena for queue UI
- add consumer to send each image to the queue
- Use GCS to upload the file
  -- create a bucket (ensure you choose fine-grained access control so you can set public:true)
  -- create service account with Storage Object Admin
  -- create GCS service and method to upload file, using @google-cloud/storage package
- Add schema for listing image and handle in consumer

## Add a listings module

Let's start by adding a listings resource. We'll use the Nest CLI to generate the module, service and controller:

```bash
npx nest generate resource modules/listing
```

Use REST API in the options and choose Y for generating CRUD entry points.

We're going to focus on the creating listings, so you can remove the other methods. You should be left with this in a listings controller:

```ts
import { Controller, Post, Body } from '@nestjs/common'
import { ListingService } from './listing.service'
import { CreateListingDto } from './dto/create-listing.dto'

@Controller('listing')
export class ListingController {
  constructor(private readonly listingService: ListingService) {}

  @Post()
  create(@Body() createListingDto: CreateListingDto) {
    return this.listingService.create(createListingDto)
  }
}
```

And this in a listings service:

```ts
import { Injectable } from '@nestjs/common'
import { CreateListingDto } from './dto/create-listing.dto'

@Injectable()
export class ListingService {
  create(createListingDto: CreateListingDto) {
    return 'This action adds a new listing'
  }
}
```

In the `listing` folder you can delete the following files:

`listing.service.spec.ts` - this is the unit testing file, we'll cover this later
`listing.controller.spec.ts` - this is the testing file for the controller, we'll cover this later in e2e tests
`entities/` - entities are for TypeORM which we're not using (we use Prisma)

You can also remove the default `app.controller.ts`, `app.controller.spec.ts` and `app.service.ts` files as these won't be needed. You'll need to remove the files and there reference in the `app.module.ts`.

Your `AppModule` should look like this:

```ts
import { Module } from '@nestjs/common'
import { CoreModule } from './core/core.module'
import { DatabaseModule } from './database/database.module'
import { ListingModule } from './modules/listing/listing.module'

@Module({
  imports: [CoreModule, DatabaseModule, ListingModule],
  controllers: [],
  providers: [],
})
export class AppModule {}
```

## Storing listings in the database

We need a way of storing the listings in the database. We'll use Prisma for this which was set up in the starter repo project.

Head into the `schema.prisma` file in the `database` directory and add the following schema:

```prisma
// This is your Prisma schema file,
// learn more about it in the docs: https://pris.ly/d/prisma-schema

generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model Listing {
  id              Int       @id @default(autoincrement())
  label           String
  addressLine1    String
  addressLine2    String?
  addressCity     String
  addressZipcode  String
  addressState    String
  price           Int
  bathrooms       Int
  bedrooms        Int
  squareMeters    Int
  createdAt       DateTime  @default(now())
  updatedAt       DateTime  @updatedAt
}
```

There will be a `User` model which is included in the starter repo by default - you can delete this model.

The schema is pretty self-explanatory. We have a `Listing` model with a number of fields.

- We're using the `@default` directive to set the `createdAt` field to the current date and time when a record is created.
- We're using the `@updatedAt` directive to set the `updatedAt` field to the current date and time when a record is updated.
- All other fields are required except for `addressLine2` which is optional.

To apply these database changes, we need to run our local migration command:

```bash
pnpm db:migrate:dev
```

You'll be prompted to name the migration. You can call it "initial migration".

You might be wondering about the listing images. We're going to store the images in Google Cloud Storage and store the public url in the database in a seperate table. We'll cover this later.

So when our `POST /listing` endpoint is used, we want to create a new listing in the database. This means the data received in the request body needs to match the schema above.

When we created the listing resource earlier, it created a DTO for us - `create-listing.dto.ts`. DTOs are for validation and transformation - perfect for this use case.

Let's update this now to manually match the schema:

```ts
import { IsInt, IsNotEmpty, IsOptional, IsString, Min } from 'class-validator'

export class CreateListingDto {
  @IsString()
  @IsNotEmpty()
  label: string

  @IsString()
  @IsNotEmpty()
  addressLine1: string

  @IsString()
  @IsNotEmpty()
  @IsOptional()
  addressLine2: string

  @IsString()
  @IsNotEmpty()
  addressCity: string

  @IsString()
  @IsNotEmpty()
  addressZipcode: string

  @IsInt()
  @Min(0)
  price: number

  @IsInt()
  @Min(0)
  bathrooms: number

  @IsInt()
  @Min(0)
  bedrooms: number

  @IsInt()
  @Min(0)
  squareMeters: number
}
```

Spin up your local server and give the `POST /listing` endpoint a test to make sure it's working as expected. You can use this JSON as an example:

```json
{
  "label": "Spacious Apartment in Downtown",
  "addressLine1": "123 Main St",
  "addressLine2": "Apt 4B",
  "addressCity": "Springfield",
  "addressZipcode": "62704",
  "price": 150000,
  "bathrooms": 2,
  "bedrooms": 3,
  "squareMeters": 120
}
```

Pass in different values and make sure you get the expected validation errors.

Before we implement the logic to actually store the listing in the database, we can make an optimisation to the DTO we just created.

The purpose of the DTO is to align the data received in the request body with the schema in the database. Right now, we've manually defined the DTO to match the schema. This is fine, but it's a bit repetitive and can be error-prone.

Prisma generates some types from the schema that we can leverage to make this easier.

If you review the database schema again, we actually need the user to provide all fields except for `id`, `createdAt` and `updatedAt`:

```prisma
// ...

model Listing {
  id              Int       @id @default(autoincrement()) // generated automatically
  label           String
  addressLine1    String
  addressLine2    String?
  addressCity     String
  addressZipcode  String
  addressState    String
  price           Int
  bathrooms       Int
  bedrooms        Int
  squareMeters    Int
  createdAt       DateTime  @default(now()) // generated automatically
  updatedAt       DateTime  @updatedAt // generated automatically
}
```

Inside the `modules/listing` directory, add a new file called `listing.types.ts` and add the following:

```ts
import { Listing as PrismaListing } from '@prisma/client'

export type CreateListingInput = Omit<PrismaListing, 'id' | 'createdAt' | 'updatedAt'>
```

This creates a type called `CreateListingInput` which is the same as the `Listing` type generated by Prisma, except it omits the `id`, `createdAt` and `updatedAt` fields.

This is super helpful because now we can use this type in our DTO and we don't have to manually define the DTO to match the schema. We can do this by using `implements` - this allows us to implement an interface or type in a class or DTO.

```ts
import { IsInt, IsNotEmpty, IsOptional, IsString, Min } from 'class-validator'
import { CreateListingInput } from '../listing.types'

export class CreateListingDto implements CreateListingInput {
  @IsString()
  @IsNotEmpty()
  label: string

  @IsString()
  @IsNotEmpty()
  addressLine1: string

  @IsString()
  @IsNotEmpty()
  @IsOptional()
  addressLine2: string

  @IsString()
  @IsNotEmpty()
  addressCity: string

  @IsString()
  @IsNotEmpty()
  addressZipcode: string

  @IsInt()
  @Min(0)
  price: number

  @IsInt()
  @Min(0)
  bathrooms: number

  @IsInt()
  @Min(0)
  bedrooms: number

  @IsInt()
  @Min(0)
  squareMeters: number
}
```

You should see a type error in your IDE:

```bash
Class 'CreateListingDto' incorrectly implements interface 'CreateListingInput'.
  Property 'addressState' is missing in type 'CreateListingDto' but required in type 'CreateListingInput'.
```

This is exactly why implementing the type is better than manually defining the DTO. We get type safety and the code is more readable! We forgot to include the `addressState` in the DTO so let's add that now:

```ts
import { IsInt, IsNotEmpty, IsOptional, IsString, Min } from 'class-validator'
import { CreateListingInput } from '../listing.types'

export class CreateListingDto implements CreateListingInput {
  @IsString()
  @IsNotEmpty()
  label: string

  @IsString()
  @IsNotEmpty()
  addressLine1: string

  @IsString()
  @IsNotEmpty()
  @IsOptional()
  addressLine2: string

  @IsString()
  @IsNotEmpty()
  addressCity: string

  @IsString()
  @IsNotEmpty()
  addressZipcode: string

  @IsString()
  @IsNotEmpty()
  addressState: string

  @IsInt()
  @Min(0)
  price: number

  @IsInt()
  @Min(0)
  bathrooms: number

  @IsInt()
  @Min(0)
  bedrooms: number

  @IsInt()
  @Min(0)
  squareMeters: number
}
```

Let's now update the `listing.service.ts` to use the DTO and create a new listing in the database:

```ts
import { Injectable } from '@nestjs/common'
import { CreateListingDto } from './dto/create-listing.dto'
import { DatabaseService } from '../../database/database.service'

@Injectable()
export class ListingService {
  constructor(private readonly databaseService: DatabaseService) {}

  async create(createListingDto: CreateListingDto) {
    return await this.databaseService.listing.create({
      data: createListingDto,
    })
  }
}
```

We've injected the `DatabaseService` to create the listing, and passed in the `CreateListingDto` to the `create` method. As it matches the `CreateListingInput` type, we don't need to do any manual mapping!

In order to inject any dependency outside of the current module, we need to ensure we've imported the respective module in the `imports` array of the `@Module` decorator in the `listing.module.ts` file:

```ts
import { Module } from '@nestjs/common'
import { ListingService } from './listing.service'
import { ListingController } from './listing.controller'
import { DatabaseModule } from '../../database/database.module'

@Module({
  imports: [DatabaseModule], // <-- add this
  controllers: [ListingController],
  providers: [ListingService],
})
export class ListingModule {}
```

Nice! Give the method a test and make sure it's working as expected.

You can spin up `pnpm db:studio` to view the database in the Prisma Studio UI and confirm the records been added.

## Attach files to POST /listing request

So, we've set up an endpoint and logic to create a real-estate listing.

Let's update the endpoint to allow the user to upload images for the listing. In the next step we'll add the logic to process the images in the background, but for now we'll just attach the files to the request.

To attach file(s) to an HTTP request, the standard way to do this is by using multipart/form-data as the content type. This content type allows for the transmission of both text and binary data in a single request.

NestJS recommends installing the @types/multer package so you have better type safety when handle multipart/form-data requests:

```bash
pnpm add -D @types/multer
```

To enable sending multipart/form-data, we need to use a built-in NestJS interceptor called `FilesInterceptor`. This interceptor allows us to intercept the request and attach files to the request body:

```ts
import { Controller, Post, Body, UseInterceptors, UploadedFiles } from '@nestjs/common'
import { ListingService } from './listing.service'
import { CreateListingDto } from './dto/create-listing.dto'
import { FilesInterceptor } from '@nestjs/platform-express'

@Controller('listing')
export class ListingController {
  constructor(private readonly listingService: ListingService) {}

  @Post()
  @UseInterceptors(FilesInterceptor(`images`))
  create(
    @Body() createListingDto: CreateListingDto,
    @UploadedFiles() files: Express.Multer.File[]
  ) {
    console.log(`Uploaded files:`, files)
    return this.listingService.create(createListingDto)
  }
}
```

Also note that we're using the `@UploadedFiles()` decorator. This is a built-in decorator that allows us to access the files that were attached to the request.

With this setup, try sending a request to the endpoint with a file attached. Instead of sending the request body in JSON or form-urlencoded, you'll need to send it as `multipart/form-data`. If you want to attach files to an HTTP request, you'll need to use `multipart/form-data` as the content type (it's also how the `FilesInterceptor` knows to intercept the request).

You should get a 400 error back!

```json
{
  "message": [
    "price must not be less than 0",
    "price must be an integer number",
    "bathrooms must not be less than 0",
    "bathrooms must be an integer number",
    "bedrooms must not be less than 0",
    "bedrooms must be an integer number",
    "squareMeters must not be less than 0",
    "squareMeters must be an integer number"
  ],
  "error": "Bad Request",
  "statusCode": 400
}
```

This is because the `CreateListingDto` expects the `price`, `bathrooms`, `bedrooms` and `squareMeters` fields to be numbers, but they're being sent as strings.

When using `multipart/form-data` as the content type, all the respective fields are sent as strings, which is why we're getting the validation error.

Let's update the DTO to transform the strings to numbers:

```ts
import { IsInt, IsNotEmpty, IsOptional, IsString, Min } from 'class-validator'
import { Type } from 'class-transformer'
import { CreateListingInput } from '../listing.types'

export class CreateListingDto implements CreateListingInput {
  // ...

  @IsInt()
  @Min(0)
  @Type(() => Number)
  price: number

  @IsInt()
  @Min(0)
  @Type(() => Number)
  bathrooms: number

  @IsInt()
  @Min(0)
  @Type(() => Number)
  bedrooms: number

  @IsInt()
  @Min(0)
  @Type(() => Number)
  squareMeters: number
}
```

The `Type` function provided by the `class-transformer` package allows us to transform the string to a number.

Give it a test and the files you attached should now be logged to the console!

Instead of logging the file in the controller, let's include it in the payload for the service method to keep all the logic in the service layer:

```ts
import { Injectable } from '@nestjs/common'
import { CreateListingDto } from './dto/create-listing.dto'
import { DatabaseService } from '../../database/database.service'

@Injectable()
export class ListingService {
  constructor(private readonly databaseService: DatabaseService) {}

  async create({ data, images }: { data: CreateListingDto; images: Express.Multer.File[] }) {
    const listing = await this.databaseService.listing.create({
      data,
    })
    for (const image of images) {
      // do something with image
      console.log(`image`, image)
    }
    return listing
  }
}
```

And then update the controller to pass the files to the service:

```ts
import { Controller, Post, Body, UseInterceptors, UploadedFiles } from '@nestjs/common'
import { ListingService } from './listing.service'
import { CreateListingDto } from './dto/create-listing.dto'
import { FilesInterceptor } from '@nestjs/platform-express'

@Controller('listing')
export class ListingController {
  constructor(private readonly listingService: ListingService) {}

  @Post()
  @UseInterceptors(FilesInterceptor(`images`))
  create(
    @Body() createListingDto: CreateListingDto,
    @UploadedFiles() files: Express.Multer.File[]
  ) {
    return this.listingService.create({
      data: createListingDto,
      images: files,
    })
  }
}
```

Nice! Let's now consider some validation we'd like to do on the file uploads:

- We only want to allow images to be uploaded (i.e. png, jpeg and jpg files)
- The files should have a max size of 1MB
- We only want to allow a maximum of 10 images to be uploaded

To achieve this validation, we can use NestJS Pipes. In fact, NestJS has some built-in pipes to help with some of the above validation. Specifically, there's the ParseFilePipe that allows us to pass in 'validators'.

NestJS has 2 built in validators, `FileTypeValidator` and `MaxFileSizeValidator`. Let's use these to validate the file type and max file size:

```ts
import { Controller, Post, Body, UseInterceptors, UploadedFiles } from '@nestjs/common'
import { ListingService } from './listing.service'
import { CreateListingDto } from './dto/create-listing.dto'
import { FilesInterceptor } from '@nestjs/platform-express'

@Controller('listing')
export class ListingController {
  constructor(private readonly listingService: ListingService) {}

  @Post()
  @UseInterceptors(FilesInterceptor(`images`))
  create(
    @Body() createListingDto: CreateListingDto,
    @UploadedFiles(
      new ParseFilePipe({
        validators: [
          new FileTypeValidator({ fileType: `.(png|jpeg|jpg)` }),
          new MaxFileSizeValidator({ maxSize: 1024 * 1024 }), // 1MB
        ],
      })
    )
    files: Express.Multer.File[]
  ) {
    return this.listingService.create({
      data: createListingDto,
      images: files,
    })
  }
}
```

Make a few requests and you should see the validation errors as expected. For example, file sizes over 1MB and file types that are not png, jpeg or jpg should return a 400 error.

There's 1 more validation layer we want to add: we only want to allow a maximum of 10 images to be uploaded.

In the NestJS documentation, it mentions the `FilesInterceptor` accepts a number to define the maximum number of images which you can apply like this:

```ts
import { Controller, Post, Body, UseInterceptors, UploadedFiles } from '@nestjs/common'
import { ListingService } from './listing.service'
import { CreateListingDto } from './dto/create-listing.dto'
import { FilesInterceptor } from '@nestjs/platform-express'

@Controller('listing')
export class ListingController {
  constructor(private readonly listingService: ListingService) {}

  @Post()
  @UseInterceptors(FilesInterceptor(`images`, 10)) // <-- add argument for max file count
  // ....
}
```

However, if you make a request exceeding this file count, you'll notice that the validation errors are not very helpful:

```json
{
  "message": "Unexpected field",
  "error": "Bad Request",
  "statusCode": 400
}
```

This isn't very helpful for the client making the request, so let's instead add our own custom pipe to handle this validation.

Other modules might need this pipe in the future, so let's add a directory called `common` inside `src`. This `common` directory will contain any shared code that can be used across the application.

Inside the `common` directory, add a new directory called `pipes` and inside that add a new file called `max-file-count.pipe.ts`:

```ts
import { PipeTransform, Injectable, BadRequestException } from '@nestjs/common'

@Injectable()
export class MaxFileCountValidationPipe implements PipeTransform {
  constructor(private readonly maxFiles: number) {}
  transform(files: Express.Multer.File[]) {
    if (files.length > this.maxFiles) {
      throw new BadRequestException(`Maximum of ${this.maxFiles} file uploads allowed`)
    }
    return files
  }
}
```

Let's now remove the argument we added earlier in the `FilesInterceptor` and instead apply this pipe to the `@UploadedFiles()` decorator:

```ts
import { Controller, Post, Body, UseInterceptors, UploadedFiles } from '@nestjs/common'
import { ListingService } from './listing.service'
import { CreateListingDto } from './dto/create-listing.dto'
import { FilesInterceptor } from '@nestjs/platform-express'

@Controller('listing')
export class ListingController {
  constructor(private readonly listingService: ListingService) {}

  @Post()
  @UseInterceptors(FilesInterceptor(`images`)) // <-- remove max count argument
  create(
    @Body() createListingDto: CreateListingDto,
    @UploadedFiles(
      new ParseFilePipe({
        validators: [
          new FileTypeValidator({ fileType: `.(png|jpeg|jpg)` }),
          new MaxFileSizeValidator({ maxSize: 1024 * 1024 }),
        ],
      }),
      new MaxFileCountValidationPipe(10) // <-- add this
    )
    files: Express.Multer.File[]
  ) {
    return this.listingService.create({
      data: createListingDto,
      images: files,
    })
  }
}
```

With some validation setup on the incoming attached files, let's now dive into the queue set up!

## Set up the Bull Queue

To set up a queue in NestJS we're going to use [Bull](https://github.com/OptimalBits/bull). Bull is a Node.js package that allows you to create and manage queues and is powered by Redis.

Bull is a Node.js package that allows you to create and manage queues and is powered by Redis.

In the NestJS starter repo, we already set up a cache module (which uses Redis), so there is a question around should we use the same Redis instance for the queue or a seperate one.

In many cases, starting with a single Redis instance might be okay during development or in low-traffic scenarios, but as the application scales, moving to separate instances might become necessary. So we're going to stick with a single Redis instance for now.

Before diving in, let's install the relevant Bull packages:

```bash
pnpm add bull @nestjs/bull
```

To set up Bull in the project, we need to register a globally available configuration for all queues. This connects to the Redis instance and sets up some default options for all queues.

As this setup is global, we're going to add it to the `CoreModule`.

Let's add a new `Queue` module that's imported to the `CoreModule` by running this command in the terminal:

```bash
npx nest generate module core/queue
```

Inside of the `queue.module.ts` file, let's register the global Bull configuration. We'll need to inject the `ConfigService` so we can access the Redis instance credentials:

```ts
import { Module } from '@nestjs/common'
import { BullModule } from '@nestjs/bull'
import { ConfigModule, ConfigService } from '@nestjs/config'

@Module({
  imports: [
    BullModule.forRootAsync({
      imports: [ConfigModule],
      useFactory: async (configService: ConfigService) => {
        const username = configService.get('redis.username')
        const password = configService.get('redis.password')
        return {
          redis: {
            host: configService.get('redis.host'),
            port: configService.get('redis.port'),
            ...(username && { username }),
            ...(password && { password }),
          },
        }
      },
      inject: [ConfigService],
    }),
  ],
})
export class QueueModule {}
```

We want to create a queue where we can send jobs to do the following:

- Upload the file to Google Cloud Storage, getting the public image url
- Store the respective public url in the database.

Let's start by registering a queue dedicated for the listing module.

Inside `listing.module.ts`, register a new queue with name `listing`:

```ts
import { Module } from '@nestjs/common'
import { ListingService } from './listing.service'
import { ListingController } from './listing.controller'
import { DatabaseModule } from '../../database/database.module'
import { BullModule } from '@nestjs/bull'

@Module({
  imports: [BullModule.registerQueue({ name: `listing` }), DatabaseModule],
  controllers: [ListingController],
  providers: [ListingService],
})
export class ListingModule {}
```

We need a way of adding jobs to the listing queue and processing jobs from the listing queue.

Inside the `listing` directory, add a new directory called `queue` and inside that add 2 new files:

1. `listing.producer.ts` - this will be for adding jobs to the queue
1. `listing.consumer.ts` - this will be for processing jobs from the queue

Let's start with the producer. Inside `listing.producer.ts`, add the following:

```ts
import { Injectable } from '@nestjs/common'
import { InjectQueue } from '@nestjs/bull'
import { Queue } from 'bull'

@Injectable()
export class ListingProducer {
  constructor(@InjectQueue(`listing`) private listingQueue: Queue) {}

  async createListingImage(image: Express.Multer.File) {
    return await this.listingQueue.add(`createListingImage`, image)
  }
}
```

Here's how the @InjectQueue decorator works:

- The decorator accepts a string argument which is the name of the queue we want to inject
- The decorator injects the queue instance into the class
- We can then use the queue instance to add jobs to the queue

For now, the payload just passes through a string but we'll tweak this shortly.

And let's add the consumer:

```ts
import { Process, Processor } from '@nestjs/bull'
import { Job } from 'bull'

@Processor(`listing`)
export class ListingConsumer {
  @Process(`createListingImage`)
  async createListingImage(job: Job<Express.Multer.File>) {
    console.log(`createListingImage filename:`, job.data.originalname)
    return job.data
  }
}
```

Let's not forget to register the producer and consumer in the `listing.module.ts` file:

```ts
import { Module } from '@nestjs/common'
import { ListingService } from './listing.service'
import { ListingController } from './listing.controller'
import { DatabaseModule } from '../../database/database.module'
import { BullModule } from '@nestjs/bull'
import { ListingProducer } from './queue/listing.producer'
import { ListingConsumer } from './queue/listing.consumer'

@Module({
  imports: [BullModule.registerQueue({ name: `listing` }), DatabaseModule],
  controllers: [ListingController],
  providers: [ListingService, ListingProducer, ListingConsumer], // <-- add producer and consumer
})
export class ListingModule {}
```

Let's now update the `listing.service.ts` to use the producer to add a job to the queue:

```ts
import { Injectable } from '@nestjs/common'
import { CreateListingDto } from './dto/create-listing.dto'
import { DatabaseService } from '../../database/database.service'
import { ListingProducer } from './queue/listing.producer'

@Injectable()
export class ListingService {
  constructor(
    private readonly databaseService: DatabaseService,
    private readonly listingQueue: ListingProducer
  ) {}

  async create({ data, images }: { data: CreateListingDto; images: Express.Multer.File[] }) {
    const listing = await this.databaseService.listing.create({
      data,
    })
    for (const image of images) {
      // send image to queue
      await this.listingQueue.createListingImage(image)
    }
    return listing
  }
}
```

Run another HTTP request and you should see the job data logged to the console.

Nice work, you've just set up a queue and added a job to it!

Before getting onto adding the logic for handling the file uploads, there are a couple of things we can do to improve our current queue set up:

1. The queue name `listing` is hard-coded in multiple places. We should use a constant instead so we can easily change the name in one place.
2. What happens if the job consumer throws an error? Let's setup some logging to automatically log all errors that happen in the queue.

Let's start with the queue name. Inside the `core/queue` directory, add a new file called `queue.constants.ts` with the following:

```ts
export const LISTING_QUEUE = `listing`
```

Now use this constant in the `listing.module.ts`:

```ts
import { Module } from '@nestjs/common'
import { ListingService } from './listing.service'
import { ListingController } from './listing.controller'
import { DatabaseModule } from '../../database/database.module'
import { BullModule } from '@nestjs/bull'
import { ListingProducer } from './queue/listing.producer'
import { ListingConsumer } from './queue/listing.consumer'
import { LISTING_QUEUE } from '../../core/queue/queue.constants'

@Module({
  imports: [BullModule.registerQueue({ name: LISTING_QUEUE }), DatabaseModule], // <-- use constant
  controllers: [ListingController],
  providers: [ListingService, ListingProducer, ListingConsumer],
})
export class ListingModule {}
```

In the producer:

```ts
import { Injectable } from '@nestjs/common'
import { InjectQueue } from '@nestjs/bull'
import { Queue } from 'bull'
import { LISTING_QUEUE } from '../../../core/queue/queue.constants'

@Injectable()
export class ListingProducer {
  constructor(@InjectQueue(LISTING_QUEUE) private listingQueue: Queue) {}

  async createListingImage(image: Express.Multer.File) {
    return await this.listingQueue.add(`createListingImage`, image)
  }
}
```

And the consumer:

```ts
import { Process, Processor } from '@nestjs/bull'
import { Job } from 'bull'
import { LISTING_QUEUE } from '../../../core/queue/queue.constants'

@Processor(LISTING_QUEUE)
export class ListingConsumer {
  @Process(`createListingImage`)
  async createListingImage(job: Job<Express.Multer.File>) {
    console.log(`createListingImage filename:`, job.data.originalname)
    return job.data
  }
}
```

In regards to setting up automatic logs for errors that happen when jobs are processed, we can leverage Bull events.

The NestJS bull package has quite a few events included out the box, like `@OnQueueFailed()` which is fired when a job fails to be processed and `@OnQueueCompleted` which is fired when a job is successfully processed.

Let's inject our custom logger and use the `@OnQueueFailed()` event to log any errors that happen when processing a job.

```ts
import { Process, Processor, OnQueueFailed } from '@nestjs/bull'
import { Job } from 'bull'
import { LISTING_QUEUE } from '../../core/queue/queue.constants'
import { Logger } from '../../core/logger/logger.service'

@Processor(LISTING_QUEUE)
export class ListingConsumer {
  constructor(private readonly logger: Logger) {}

  @Process(`createListingImage`)
  async createListingImage(job: Job<Express.Multer.File>) {
    console.log(`createListingImage filename:`, job.data.originalname)
    return job.data
  }

  @OnQueueFailed()
  async onError(job: Job<string>, error: any) {
    this.logger.error(
      `Failed job ${job.id} of type ${job.name}: ${error.message}`,
      error.stack,
      `Queue`,
      job.data
    )
  }
}
```

If you'd like to give it a test, throw an error in the `createListingImage` method and you should see the error logged to the console.

This works well, but as soon we add more jobs and/or queues, we'll have to repeat this code for each queue.

A nicer way of handling this is by creating a BaseConsumer class that all other consumers can extend from. This way, we can define the error handling logic in one place and all other consumers will inherit it.

In the `core/queue` directory, add a new file called `base.consumer.ts`:

```ts
import { OnQueueFailed } from '@nestjs/bull'
import { Job } from 'bull'
import { Logger } from '../logger/logger.service'

export abstract class BaseConsumer {
  constructor(private readonly logger: Logger) {}
  @OnQueueFailed()
  onError(job: Job<any>, error: any) {
    this.logger.error(
      `Failed job ${job.id} of type ${job.name}: ${error.message}`,
      error.stack,
      `Queue`,
      job.data
    )
  }
}
```

Note that I've used `abstract` here. This is because we don't ever want to instantiate this class directly, we just want to extend from it.

Let's now update the `listing.consumer.ts` to extend from this class:

```ts
import { Process, Processor, OnQueueFailed } from '@nestjs/bull'
import { Job } from 'bull'
import { LISTING_QUEUE } from '../../core/queue/queue.constants'
import { Logger } from '../../core/logger/logger.service'
import { BaseConsumer } from '../../core/queue/base.consumer'

@Processor(LISTING_QUEUE)
export class ListingConsumer extends BaseConsumer {
  constructor(logger: Logger) {
    super(logger)
  }

  @Process(`createListingImage`)
  async createListingImage(job: Job<Express.Multer.File>) {
    console.log(`createListingImage filename:`, job.data.originalname)
    return job.data
  }

  // @OnQueueFailed()
  // async onError(job: Job<string>, error: any) {
  //   this.logger.error(
  //     `Failed job ${job.id} of type ${job.name}: ${error.message}`,
  //     error.stack,
  //     `Queue`,
  //     job.data
  //   )
  // }
}
```

Note I've had to remove the `private readonly` from the constructor argument as this is not allowed when using `super` in a constructor.

Nice! Our error logging inside jobs is not centralised.

On a side note, there might be a scenario where you want to add some logic to the `onError` method in a specific consumer. In this case, you can override the `onError` method in the consumer and add the logic there like this:

```ts
import { Process, Processor, OnQueueFailed } from '@nestjs/bull'
import { Job } from 'bull'
import { LISTING_QUEUE } from '../../core/queue/queue.constants'
import { Logger } from '../../core/logger/logger.service'
import { BaseConsumer } from '../../core/queue/base.consumer'

@Processor(LISTING_QUEUE)
export class ListingConsumer extends BaseConsumer {
  constructor(logger: Logger) {
    super(logger)
  }

  @Process(`createListingImage`)
  async createListingImage(job: Job<Express.Multer.File>) {
    console.log(`createListingImage filename:`, job.data.originalname)
    return job.data
  }

  @OnQueueFailed()
  async onError(job: Job<UploadListingImageDto>, error: any) {
    super.onError(job, error)
    // do something else here
  }
}
```

Great work! We've setup a queue and added a job to it. In the next step, we'll see how we can visualize this queue using Bull Arena.

## Setting up Bull Board

Let's add a way to visualize the queue and jobs in the browser.

This is useful for development and debugging, but also for production as it allows you to monitor the queue and jobs in real-time.

We're going to use [Bull Board](https://github.com/felixmosh/bull-board/tree/master) to achieve this - the most popular UI tool to visualize Bull queues.

Let's start by installing the relevant packages:

```bash
pnpm add @bull-board/nestjs @bull-board/api @bull-board/express
```

Let's start by registering the Bull Board instance in the `QueueModule` we setup earlier:

```ts
import { Module } from '@nestjs/common'
import { BullModule } from '@nestjs/bull'
import { ConfigModule, ConfigService } from '@nestjs/config'
import { BullBoardModule } from '@bull-board/nestjs'
import { ExpressAdapter } from '@bull-board/express'

@Module({
  imports: [
    BullModule.forRootAsync({
      imports: [ConfigModule],
      useFactory: async (configService: ConfigService) => {
        const username = configService.get('redis.username')
        const password = configService.get('redis.password')
        return {
          redis: {
            host: configService.get('redis.host'),
            port: configService.get('redis.port'),
            ...(username && { username }),
            ...(password && { password }),
          },
        }
      },
      inject: [ConfigService],
    }),
    BullBoardModule.forRoot({
      route: `/queues`,
      adapter: ExpressAdapter,
    }),
  ],
})
export class QueueModule {}
```

**Important to note:** If you want to add some authentication to restrict access to the `/queues` route, you can use the `middleware` option and pass in an Express middleware function.

Similar to Bull, with each queue you define you also need to register a Bull Board instance for that queue so it shows up in the UI.

In the `ListingModule`, register a Bull Board instance for the `listing` queue. We can leverage the `LISTING_QUEUE` constant we setup earlier:

```ts
import { Module } from '@nestjs/common'
import { ListingService } from './listing.service'
import { ListingController } from './listing.controller'
import { DatabaseModule } from '../../database/database.module'
import { BullModule } from '@nestjs/bull'
import { ListingProducer } from './queue/listing.producer'
import { ListingConsumer } from './queue/listing.consumer'
import { LISTING_QUEUE } from '../../core/queue/queue.constants'
import { BullBoardModule } from '@bull-board/nestjs'
import { BullAdapter } from '@bull-board/api/bullAdapter'

@Module({
  imports: [
    BullModule.registerQueue({ name: LISTING_QUEUE }),
    BullBoardModule.forFeature({
      name: LISTING_QUEUE,
      adapter: BullAdapter,
    }),
    DatabaseModule,
  ],
  controllers: [ListingController],
  providers: [ListingService, ListingProducer, ListingConsumer],
})
export class ListingModule {}
```

And that's it! Spin up your local server and go to `/queues` in your browser. You'll see the `listing` queue listed there along with the jobs that have been added to it.

An optional step:

You might've noticed when you visit the `/queues` route in your browser, the respective HTTP requests are logged to the console.

For local development, this can cause quite a few logs to be printed to the console. If you'd like to disable this, you tweak the existing `LoggerMiddleware` like this:

```ts
import { Injectable, NestMiddleware } from '@nestjs/common'
import { Request, Response, NextFunction } from 'express'
import { Logger } from './logger.service'
import { ConfigService } from '@nestjs/config'

@Injectable()
export class LoggerMiddleware implements NestMiddleware {
  constructor(private readonly logger: Logger, private readonly configService: ConfigService) {}

  use(req: Request, res: Response, next: NextFunction) {
    const environment = this.configService.get(`environment`)
    const isQueueRoute = req.url.startsWith('/queue') // <-- Check if the URL starts with /queue
    if (!isQueueRoute && environment !== `test`) {
      const start = Date.now()
      const { method, url, headers, query, body } = req

      res.on('finish', () => {
        const responseTime = Date.now() - start
        const message = `${method} ${url} ${res.statusCode} ${responseTime}ms`
        const statusCode = res.statusCode
        const logData = {
          responseTime,
          method,
          url,
          headers,
          query,
          body,
        }

        if (statusCode >= 500) {
          this.logger.error(message, undefined, `HTTP`, logData)
        } else if (statusCode >= 400) {
          this.logger.warn(message, `HTTP`, logData)
        } else {
          this.logger.log(message, `HTTP`, logData)
        }
      })
    }
    next()
  }
}
```

And that's it! Now you won't have the HTTP requests logged to the console when visiting any `/queues/*` route.

## Handling files in the queue

- Discuss trade-offs of saving files to disk vs uploading image to job queue
- Update controller to save files to disk
- Add custom exception filter
- Handle failed jobs
- Handle successful jobs
- Service for GCS

## Process the job: upload to GCS and store url in database

In NestJS, it's typically best practice to handle your validation in the controller layer and then pass the validated data to the service layer to handle the business logic.

It's also best practice to do something similar when processing jobs:

1. In the job, validate the incoming payload
2. Pass the validated payload to the service layer to handle the business logic

- validate the job payload
- upload file to GCS
- store url in database in new table

### Understand how the file upload works

The confusion you're experiencing is completely understandable, especially if you're used to working with certain libraries or systems where you pass around actual file objects or streams. The underlying magic here is the combination of the Google Cloud Storage Node.js client library and how Node.js handles file I/O.

Let's break this down:

Node.js File I/O: In Node.js, file operations are typically handled using paths rather than loading entire files into memory. This is efficient, especially for larger files, because it avoids excessive memory consumption. When you do operations on a file in Node.js, you often provide the path to the file, and the operation reads from or writes to that path directly.

Google Cloud Storage Client Library: The GCS Node.js client library is designed to work seamlessly with the Node.js way of handling files. When you call the bucket.upload(filePath) method, under the hood, the library:

Opens a read stream for the file at the given filePath.
Reads the file in chunks.
Sends those chunks to GCS until the entire file is uploaded.
This is abstracted away from the developer for simplicity, but that's roughly what's happening.

Why not the file itself?: It's common in web development (especially on the frontend or with certain backend frameworks) to deal with file objects, especially when users upload files via a web interface. However, in a server environment and especially when dealing with file storage systems or databases, it's often more efficient to work with paths or streams. Loading an entire large file into memory can be resource-intensive and slow.

File Paths are Versatile: By accepting a file path, the method allows for a range of use cases. You can pass in the path to a file that's just been uploaded by a user, a path to a file generated by your application, or even a path to a static file that's part of your application.

In summary, the approach used in the provided code is idiomatic for Node.js and is designed for efficiency and flexibility. The GCS library does the heavy lifting of streaming the file from disk and uploading it in chunks to Google Cloud Storage.

- Uploading csv files and validating them
  -- implement abstracted csv service
- Defining imports schema and storing record to database
- Loop over each row and send it to listings queue for processing
- We have no way of creating listings, so create listings module and service
- Add a listing producer to send listings to queue
- In the imports module, use listings producer to send listings to queue
- Create a consumer to process listings in listings module
- Bonus: storing respective csv file in S3 bucket
<!-- - Send file off to queue for processing. Queue can be defined -->

```

```
